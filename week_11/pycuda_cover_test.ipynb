{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49768d2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35, 35)\n",
      "[[1. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[[1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " ...\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]]\n",
      "[[1. 1. 1. ... 1. 1. 0.]\n",
      " [1. 1. 1. ... 1. 1. 0.]\n",
      " [1. 1. 1. ... 1. 1. 0.]\n",
      " ...\n",
      " [1. 1. 1. ... 1. 1. 0.]\n",
      " [1. 1. 1. ... 1. 1. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pycuda.autoinit\n",
    "import pycuda.driver as cuda\n",
    "from pycuda.compiler import SourceModule\n",
    "import pycuda.gpuarray as gpuarray\n",
    "\n",
    "BLOCK_SIZE = 32\n",
    "\n",
    "# cuda blocks and grids are set to cover all indexes. So there are surplus processes that should not be performed. This function confirms that there are enough processes that cover all necessary indexes. \n",
    "def cuda_cover_test():\n",
    "    n = 35\n",
    "    ni = np.int32(n)\n",
    "    x = np.empty([n,n]).astype(np.float32)\n",
    "\n",
    "    # allocate memory on device\n",
    "    x_gpu = cuda.mem_alloc(x.nbytes)\n",
    "\n",
    "    # compile kernel\n",
    "    mod = SourceModule(open(\"kernels.cu\", \"r\").read())\n",
    "\n",
    "    # get function\n",
    "    cuda_cover_test = mod.get_function(\"cuda_cover_test\");\n",
    "\n",
    "    # set grid size\n",
    "    n1 = 10\n",
    "    n2 = 15\n",
    "    if n2%BLOCK_SIZE != 0 and n1%BLOCK_SIZE != 0:\n",
    "        grid=(n2//BLOCK_SIZE+1,n1//BLOCK_SIZE+1,1)\n",
    "    elif n2%BLOCK_SIZE == 0 and n1%BLOCK_SIZE != 0:\n",
    "        grid=(n2//BLOCK_SIZE,n1//BLOCK_SIZE+1,1)\n",
    "    elif n2%BLOCK_SIZE != 0 and n1%BLOCK_SIZE == 0:\n",
    "        grid=(n2//BLOCK_SIZE+1,n1//BLOCK_SIZE,1)\n",
    "    else:\n",
    "        grid=(n2//BLOCK_SIZE,n1//BLOCK_SIZE,1)\n",
    "\n",
    "    # print('grid:', grid)   # must be integers\n",
    "\n",
    "    # call gpu function\n",
    "    cuda_cover_test(x_gpu, ni, block=(BLOCK_SIZE,BLOCK_SIZE,1), grid=grid)\n",
    "    cuda.Context.synchronize()\n",
    "\n",
    "    # copy back the result\n",
    "    cuda.memcpy_dtoh(x, x_gpu)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "x_test = cuda_cover_test()\n",
    "\n",
    "print(x_test.shape)\n",
    "print(x_test)\n",
    "print(x_test[0:32,0:32])\n",
    "print(x_test[0:33,0:33])\n",
    "# The indexes in the cuda function covers the size of block! (not the predefined n1 or n2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fae5454",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
